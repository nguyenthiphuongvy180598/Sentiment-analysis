from preprocess import  wrong_items
from html.parser import HTMLParser
from itertools import groupby
import pdb
import re



"""html_parser = HTMLParser()
tweet =  "I luv my <3 iphone & you're awsm apple. DisplayIsAwesome, sooo happppppy ðŸ™‚ http://www.apple.com happpy"
words = tweet.split()
reformed = [wrong_items[word] if word in wrong_items else word for word in words]
reformed = " ".join(reformed)
cleaned = " ".join(re.findall('[A-Z][^A-Z]*', reformed))
final = re.sub(r'http\S+', '', cleaned)
pdb.set_trace()"""
s = "Ko <3 NgonQuaa quaÌ may Ä‘oan_trang  Ä‘iiiiiii http://www.google.com Nhi Ì€ n chung qua Ì n kha Ì nho Ì‰ , nÃ´ Ì£ i thÃ¢ Ì t tÆ°Æ¡i tÄƒ Ì n , teen va Ì€ Ä‘c trag bi Ì£ ma Ì y Ä‘iÃª Ì€ u ho Ì€ a kha Ì ma Ì t , ... hÃ¢ Ì p dÃ¢ Ì‰ n ko chi Ì‰ vc bÃ´ Ì tri Ì ba Ì€ n ghÃª Ì nho Ì‰ go Ì£ n , ma Ì€ co Ì€ n Æ¡ Ì‰ hi Ì€ nh thÆ° Ì c mo Ì n Äƒn , Ä‘Ã´ Ì€ uÃ´ Ì g cu Ìƒ ng kha Ì bÄƒ Ì t mÄƒ Ì t ... mui vi Ì£ thi Ì€ ca Ì c ba Ì£ n ha Ìƒ y tÆ° Ì£ mi Ì€ nh tra Ì‰ i nghiÃª Ì£ m nhk , Ä‘Ã´ Ì i vs mi Ì€ h thi Ì€ thÆ° Ì c Äƒn Ä‘Ã´ Ì€ uÃ´ Ì g Æ¡ Ì‰ Ä‘Ã¢y vÆ° Ì€ a vs tu Ì i tiÃª Ì€ n , nhÃ¢ Ì t la Ì€ sinh_viÃªn , ... nÃª Ì u ba Ì£ n bo Ì‰ qua ko Ä‘c rÃ´ Ì£ g thi Ì€ Ä‘Ã¢y la Ì€ nÆ¡i kha Ì li Ì tÆ°Æ¡ Ì‰ ng Ä‘Ãª Ì‰ Ä‘Ãª Ì n trog nhÆ° Ìƒ g nga Ì€ y nÄƒ Ì ng no Ì g : ) "
from preprocess.nlp import VietnamProcess

pre = VietnamProcess(s)
pre.remove_urls()
"""icon """
pre.normalization()
pre.slip_attached_words()

pre.replace_emotion_icons()
"""dÃ¢Ìu"""
pre.remove_punctuations()
pre.tokenize()
pre.standardizing()
"""wrongs"""
pre.replace_wrong_items()

"""pre.remove_stopwords()
print(pre.sentence)

pre.replace_not_terms()
print(pre.sentence)"""




